# Solar Sessions â€” Rant & Reflect (Next.js + Whisper + Gemini)

This folder contains the Next.js app for Solar Sessions with an integrated "Rant & Reflect" feature â€” a voice-first emotional reflection tool that uses OpenAI Whisper for speech-to-text and Google Gemini for emotion analysis.

This README is focused on the Rant & Reflect integration and how to run it locally.

## Features

- Record short voice rants in the browser (MediaRecorder).
- Transcribe audio with OpenAI Whisper (server-side API route).
- Analyze emotional tone with Google Gemini (server-side API route).
- Minimal, reactive UI components: `Recorder`, `TranscriptView`, `EmotionCard`.

## File highlights

- `app/rant-reflect/page.tsx` â€” Rant & Reflect UI and orchestration.
- `app/api/transcribe/route.ts` â€” serverless API route that accepts an audio `FormData` upload, calls Whisper and Gemini helpers, and returns the combined result.
- `lib/whisper.ts` â€” Whisper helper wrapper for OpenAI audio transcription.
- `lib/gemini.ts` â€” Gemini helper wrapper for emotion analysis.
- `components/Recorder.tsx`, `components/TranscriptView.tsx`, `components/EmotionCard.tsx` â€” frontend UI pieces.

## Environment variables

Create a `.env.local` in the `solar-sessions` folder with the following variables (or set them in your hosting platform):

```
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
GEMINI_API_KEY=ya29.a0AfH6S... (or your Gemini credential)
# Optional: other keys your project needs (e.g. Supabase)
```

For convenience, a `.env.example` is included alongside this README.

## Local development (quick start)

1. Install dependencies

```bash
# From the solar-sessions folder
npm install
# or
pnpm install
```

2. Add your API keys to `.env.local`.

3. Start the dev server

```bash
npm run dev
# or
pnpm dev
```

4. Open `http://localhost:3000/rant-reflect` and test the recorder.

Notes:
- The transcription route expects a `POST` with a `FormData` field named `audio` (file). The page already sends `recording.webm` from the browser.
- Keep audio sessions under 25MB to avoid serverless size limits.

## Troubleshooting

- If imports like `@/lib/whisper` cannot be resolved, ensure your `tsconfig.json` or `jsconfig.json` has `baseUrl`/`paths` configured.
- If the Whisper or Gemini calls fail, check your env vars and API key scopes.

## Next steps (suggested)

- Add end-to-end tests for the transcription API using a small sample audio fixture.
- Add persisted session history (Supabase/Postgres) to track emotional trends.
- Implement real-time streaming transcription for more immediacy.

---

If you'd like, I can also:
- Add a `.github/workflows` CI job that runs TypeScript checks and lints.
- Add a small E2E test that POSTs a short audio file to the API route.
# ğŸŒŸ Solar Sessions

> **Visualize Your Day Through Space & Reflect on Your Emotions with AI**

Solar Sessions is an innovative full-stack Next.js application that combines **3D space visualization** of your daily activities with **AI-powered emotional reflection** through voice. Transform your sessions into an interactive solar system and use the integrated **Rant & Reflect** feature to speak freely and receive intelligent emotional insights.

---

## ğŸ¯ **Project Overview**

**Solar Sessions** offers two core experiences:

### 1. ğŸª **Solar System Visualization**
Transform your daily sessions into beautiful 3D planets orbiting in space. Each planet represents a work session, and moons represent emotions associated with that session.

### 2. ğŸ§ **Rant & Reflect (AI Emotional Analysis)**
An AI-driven self-therapy tool that allows users to:
- **Record voice rants** directly in the browser
- **Transcribe speech to text** using OpenAI's Whisper API
- **Analyze emotional tone** using Google's Gemini Pro AI
- **Receive personalized insights** and suggestions for emotional wellness

---

## âœ¨ **Key Features**

### Rant & Reflect Module
* ğŸ™ï¸ **Voice Recording Interface** - Record audio directly from the browser using Web Audio API
* ğŸ§¾ **Speech-to-Text Conversion** - Whisper automatically transcribes user speech with high accuracy
* ğŸ’¬ **Emotion Classification** - Gemini analyzes emotional tone (calm, angry, anxious, hopeful, etc.)
* ğŸ’¡ **AI Insights** - Get compassionate suggestions based on your emotional state
* âš¡ **Instant Feedback** - Real-time transcription and analysis
* ğŸ“Š **Intensity Scoring** - Emotion intensity rated on a 1-10 scale

### Solar Sessions Core
* ğŸŒŒ **3D Space Environment** - Beautiful space visualization with Three.js
* ğŸ” **Authentication** - Secure user authentication with Supabase
* ğŸ“… **Calendar Integration** - Track and visualize sessions over time
* ğŸ¨ **Beautiful UI** - Modern, responsive design with smooth animations

---

## ğŸ› ï¸ **Tech Stack**

| Layer                  | Technology                              |
| ---------------------- | --------------------------------------- |
| **Framework**          | Next.js 15 (App Router)                 |
| **Frontend**           | React 19, TypeScript, TailwindCSS       |
| **3D Graphics**        | Three.js, React Three Fiber             |
| **Backend**            | Next.js API Routes (Serverless)         |
| **Authentication**     | Supabase                                |
| **Speech Recognition** | OpenAI Whisper (`whisper-1`)            |
| **Emotion Analysis**   | Google Gemini Pro                       |
| **Audio Capture**      | MediaRecorder API (WebRTC)              |
| **Deployment**         | Vercel (Recommended)                    |

---

## ğŸ“‚ **Project Structure**

```
solar-sessions/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx                        # Home page
â”‚   â”œâ”€â”€ layout.tsx                      # Root layout with navbar & auth
â”‚   â”œâ”€â”€ rant-reflect/
â”‚   â”‚   â””â”€â”€ page.tsx                    # Rant & Reflect main page
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ transcribe/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts                # Whisper + Gemini API endpoint
â”‚   â”‚   â””â”€â”€ health/
â”‚   â”‚       â””â”€â”€ route.ts                # Health check endpoint
â”‚   â”œâ”€â”€ login/
â”‚   â”‚   â””â”€â”€ page.tsx                    # Login page
â”‚   â”œâ”€â”€ signup/
â”‚   â”‚   â””â”€â”€ page.tsx                    # Signup page
â”‚   â””â”€â”€ dummy/                          # Sample session pages
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ NavBar.tsx                      # Navigation bar
â”‚   â”œâ”€â”€ AuthModal.tsx                   # Authentication modal
â”‚   â”œâ”€â”€ SpaceBackground.tsx             # 3D space visualization
â”‚   â”œâ”€â”€ Recorder.tsx                    # Audio recording component
â”‚   â”œâ”€â”€ TranscriptView.tsx              # Display transcription
â”‚   â”œâ”€â”€ EmotionCard.tsx                 # Display emotion analysis
â”‚   â””â”€â”€ Loader.tsx                      # Loading animation
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ whisper.ts                      # OpenAI Whisper integration
â”‚   â”œâ”€â”€ gemini.ts                       # Google Gemini integration
â”‚   â””â”€â”€ supabase.ts                     # Supabase client setup
â”‚
â”œâ”€â”€ contexts/
â”‚   â””â”€â”€ AuthContext.tsx                 # Authentication context
â”‚
â”œâ”€â”€ public/                             # Static assets
â”œâ”€â”€ .env.local                          # Environment variables
â”œâ”€â”€ next.config.ts                      # Next.js configuration
â”œâ”€â”€ package.json                        # Dependencies
â””â”€â”€ README.md                           # This file
```

---

## ğŸš€ **Getting Started**

### Prerequisites
- Node.js 18+ installed
- npm or yarn package manager
- OpenAI API key (for Whisper)
- Google Gemini API key
- Supabase account (optional, for auth features)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/SolarSessions.git
   cd SolarSessions/solar-sessions
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Configure environment variables**
   
   Create a `.env.local` file in the root directory:
   ```env
   # Supabase (Optional - for authentication)
   NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
   NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key

   # OpenAI Whisper API (Required for Rant & Reflect)
   OPENAI_API_KEY=your_openai_api_key

   # Google Gemini API (Required for emotion analysis)
   GEMINI_API_KEY=your_gemini_api_key
   ```

4. **Run the development server**
   ```bash
   npm run dev
   ```

5. **Open in browser**
   Navigate to [http://localhost:3000](http://localhost:3000)

---

## ğŸ§ **Using Rant & Reflect**

1. Navigate to **Rant & Reflect** from the navbar
2. Click the **"START"** button to begin recording
3. Speak freely about your thoughts, feelings, or experiences
4. Click **"STOP"** when finished
5. Wait for AI processing (usually 5-15 seconds)
6. View your:
   - ğŸ“ **Transcription** - What you said
   - ğŸ’­ **Emotion** - Detected emotional state
   - ğŸ“Š **Intensity** - How strong the emotion is (1-10)
   - ğŸ’¡ **Insights** - Helpful suggestions from AI
7. Click **"Record Another"** to start a new session

---

## ğŸ§  **How It Works**

### Rant & Reflect Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Speaks  â”‚
â”‚   (Browser)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio Blob
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /api/      â”‚
â”‚  transcribe      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Whisper â”‚ â”€â”€â–º Transcribed Text
    â”‚   API   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Gemini  â”‚ â”€â”€â–º Emotion Analysis
    â”‚   Pro   â”‚     (emotion, intensity, suggestions)
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JSON Response   â”‚
â”‚ to Frontend     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API Response Format
```json
{
  "text": "I've been feeling overwhelmed by work lately...",
  "emotion": "stressed",
  "confidence": "8",
  "suggestions": "Take regular breaks and practice mindfulness.",
  "timestamp": "2025-10-18T16:25:00Z",
  "processingTime": "7.32s",
  "fileSize": "156.78 KB"
}
```

---

## ğŸ“¡ **API Endpoints**

### `POST /api/transcribe`
Upload audio file and receive transcription + emotion analysis.

**Request:**
- Method: `POST`
- Content-Type: `multipart/form-data`
- Body: `audio` (File, max 25MB)

**Response:**
```json
{
  "text": "string",
  "emotion": "string",
  "confidence": "string",
  "suggestions": "string",
  "timestamp": "ISO string",
  "processingTime": "string",
  "fileSize": "string"
}
```

### `GET /api/health`
Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "ISO string",
  "service": "Solar Sessions API",
  "version": "1.0.0"
}
```

---

## ğŸ¨ **Features & Components**

### Recorder Component
- Real-time recording with visual feedback
- Timer display during recording
- Microphone permission handling
- Audio blob generation

### Emotion Card
- Color-coded by emotion type
- Emoji representation
- Intensity meter (1-10)
- AI-generated insights

### Transcript View
- Clean, readable text display
- Quotation formatting
- Smooth animations

---

## ğŸ”’ **Security & Privacy**

- Audio files are **not stored** on servers
- Processing happens in real-time via API
- All data transmission uses HTTPS
- Environment variables protect API keys
- Supabase handles authentication securely

---

## ğŸŒ **Deployment**

### Deploy to Vercel (Recommended)

1. Push your code to GitHub
2. Go to [vercel.com](https://vercel.com)
3. Import your repository
4. Add environment variables in Vercel dashboard
5. Deploy!

Vercel automatically handles:
- Serverless API routes
- Edge caching
- Automatic HTTPS
- Zero-config deployment

---

## ğŸš§ **Future Enhancements**

- [ ] ğŸ”„ **Real-time streaming transcription**
- [ ] ğŸ“Š **Emotion tracking dashboard over time**
- [ ] ğŸ—„ï¸ **Save rant history to database**
- [ ] ğŸ§˜ **Personalized wellness recommendations**
- [ ] ğŸŒ **Multilingual support**
- [ ] ğŸ“± **Mobile app version**
- [ ] ğŸ”— **Integration with calendar for mood tracking**
- [ ] ğŸ¯ **Goal setting based on emotional patterns**

---

## ğŸ¤ **Contributing**

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ **License**

This project is open source and available under the MIT License.

---

## ğŸ™ **Acknowledgments**

- **OpenAI** for the Whisper speech recognition model
- **Google** for the Gemini Pro AI model
- **Vercel** for the amazing Next.js framework
- **Three.js** for 3D graphics capabilities
- **Supabase** for authentication infrastructure

---

## ğŸ“§ **Contact**

For questions, suggestions, or feedback:
- Create an issue on GitHub
- Email: your-email@example.com

---

## ğŸ¯ **Summary**

**Solar Sessions** combines cutting-edge AI technology with beautiful 3D visualization to create a unique self-reflection and productivity tracking experience. The **Rant & Reflect** module demonstrates how AI can be used compassionately to help people understand their emotions better.

By merging:
- ğŸ¤ **Speech recognition (Whisper)**
- ğŸ§  **Emotional intelligence (Gemini)**
- ğŸŒŒ **3D visualization (Three.js)**
- âš¡ **Seamless full-stack integration (Next.js)**

We've created a powerful tool for **mental wellness** and **self-awareness** in the modern digital age.

---

**Built with â¤ï¸ by the Solar Sessions Team**
